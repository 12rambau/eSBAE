{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0feaab2-f8e9-4db0-998c-fea1029764cf",
   "metadata": {},
   "source": [
    "### SBAE notebook series - Part I - Sample size determination\n",
    "\n",
    "The code snippets in this notebook will give a first idea of expected deforestation within a predefined Area of Interest based on Global Forest Cover data (Hansen et al 2013) for a given period of time.\n",
    "\n",
    "Based on those deforestation estimates we can calculate the sample size based on an expected sampling error. In afirst step we apply the sample size calculation from Cochran.\n",
    "\n",
    "Now that we have a rough idea of how much samples are needed, and thus how dense we need to sample our area, in order to arrive at a certain error, we re-run a sample simulation on the GFC data itself to see how much the expected error differs there.\n",
    "\n",
    "Both analysis shall give us confidence in selecting an adequte sample size tat we can use in the following notebook, where we the actual sampling design is going to be created.\n",
    "\n",
    "- todo\n",
    "- write output to markdown to create a document\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c509629a-2546-456b-b696-e7299b87bf66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from retrying import retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c2ac278-a896-4d53-8b04-7888b6728ad1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# period of change\n",
    "start_year = 2015\n",
    "end_year = 2020\n",
    "\n",
    "# forest definition\n",
    "tree_cover = 20         # in percent\n",
    "mmu = 0.5               # in hectare\n",
    "\n",
    "# aoi (various options)\n",
    "\n",
    "# based on earth engine feature collection\n",
    "country = 'Papua New Guinea'\n",
    "gaul = ee.FeatureCollection(\"FAO/GAUL/2015/level1\")\n",
    "aoi = gaul.filter(ee.Filter.eq(\"ADM0_NAME\", country)).union()\n",
    "\n",
    "# any ogr/gdal readable vectorfile (e.g. shp, gpkg, geojson, kml)\n",
    "#local_file = 'path/to/local/file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ff1426b-f667-4736-9581-fc19c7b7cc01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def apply_MMU(image, mmu=5):\n",
    "    \n",
    "    mask = image.gt(0).connectedPixelCount(ee.Number(mmu).add(2)).gte(ee.Number(mmu));\n",
    "    return image.updateMask(mask);\n",
    "\n",
    "def mmu_in_pixels(ha, scale):\n",
    "    \n",
    "    sqm = ha/100*1000*1000\n",
    "    sqm_scale = scale*scale\n",
    "    mmu = np.floor(sqm/sqm_scale)\n",
    "    print(mmu)\n",
    "    return mmu\n",
    "    \n",
    "def get_aoi_areas(aoi, collection, start=2001, end=2022, tree_cover=20, mmu=0.5):\n",
    "    \n",
    "    if collection == 'CCI':\n",
    "\n",
    "        lc = ee.ImageCollection(\"users/amitghosh/sdg_module/esa/cci_landcover\")\n",
    "        lc_start = lc.filter(ee.Filter.eq(\"system:index\", f'{start}')).first()\n",
    "        lc_end = lc.filter(ee.Filter.eq(\"system:index\", f'{end}')).first()\n",
    "        change = lc_start.neq(lc_end).clip(aoi)\n",
    "        scale = 300\n",
    "\n",
    "    elif collection == 'GFC':\n",
    "        \n",
    "        scale = 30\n",
    "        hansen = ee.Image(\"UMD/hansen/global_forest_change_2021_v1_9\")\n",
    "        loss = hansen.select('lossyear').unmask(0)\n",
    "        change = loss.gte(ee.Number(start).subtract(2000)).And(loss.lte(ee.Number(end).subtract(2000)))\n",
    "        forest = hansen.select('treecover2000').updateMask(\n",
    "            loss.gte(ee.Number(start).subtract(2000)).Or(loss.eq(0))\n",
    "        ).gte(tree_cover).unmask(0)\n",
    "        \n",
    "        \n",
    "    # -----------------------------------------------------------------\n",
    "    # getting total area of change\n",
    "    total_image = forest.addBands(change).addBands(ee.Image(1)).multiply(ee.Image.pixelArea()).rename(['forest_area', 'change_area', 'total_area'])\n",
    "    areas = total_image.reduceRegion(**{\n",
    "            'reducer': ee.Reducer.sum(),\n",
    "            'geometry': aoi,\n",
    "            'scale': scale,\n",
    "            'maxPixels': 1e14\n",
    "        })\n",
    "    \n",
    "    \n",
    "    d, areas = {}, areas.getInfo()\n",
    "    for area in areas.keys():\n",
    "        d[area] = np.round(areas[area]/1000000,2)\n",
    "    \n",
    "    span = end-start+1\n",
    "    print(f\"According to the GFC product, the Area of Interest covers an area of {d['total_area']} square kilometers,\"\n",
    "          f\" of which {d['forest_area']} square kilometers have been forested in {start} ({np.round(d['forest_area']/d['total_area']*100, 2)} %).\"\n",
    "          f\" Between {start} and {end}, {d['change_area']} square kilometers have been deforested.\"\n",
    "          f\" That corresponds to {d['change_area']/span} square kilometers of annual deforestation in average.\"    \n",
    "    )\n",
    "    \n",
    "    return d\n",
    "\n",
    "#area_dict = get_aoi_areas(aoi, 'GFC', start_year, end_year, tree_cover)\n",
    "#yearly_dict = get_yearly_deforest_stats(aoi, 'GFC')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebcddef-9c0c-453d-a3c2-20fb200de9be",
   "metadata": {},
   "source": [
    "According to the GFC product, the Area of Interest covers an area of 1129313.5 square kilometers, of which 161807.49 square kilometers have been forested in 2015 (14.33 %). Between 2015 and 2020, 2233.28 square kilometers have been deforested. That corresponds to 372.21333333333337 square kilometers of annual deforestation in average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b7630b-11b7-460c-8eae-9186315b0fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_sample_size_cochran(total_area, subarea, z_score=1.95, target_precision=0.1):\n",
    "    \n",
    "    # we calculate our proportion of change \n",
    "    proportional_change = subarea/total_area\n",
    "    \n",
    "    # our relative error\n",
    "    error = target_precision * proportional_change\n",
    "    \n",
    "    # the upper term of Cochran (SE???)\n",
    "    se = z_score*z_score * proportional_change * (1 - proportional_change) \n",
    "    \n",
    "    return se/(error**2)\n",
    "\n",
    "\n",
    "# we should invert that to do something similar as extrating from global data\n",
    "def calculate_error_cochran(total_area, subarea, z_score=1.96, sample_size=250):\n",
    "    \n",
    "    proportional_change = subarea/total_area\n",
    "    \n",
    "    se = np.sqrt(proportional_change * (1 - proportional_change) / sample_size)\n",
    "    \n",
    "    ci = z_score * se\n",
    "    \n",
    "    return ci/proportional_change*100\n",
    "\n",
    "def add_stats(row, actual_proportional):\n",
    "    \n",
    "    #abs_errors = [np.abs(np.subtract(i, actual_proportional)) for i in row['proportional_changes_sampled']]\n",
    "    #mean_deviation, sd_deviation = np.nanmean(abs_errors), np.nanstd(abs_errors)\n",
    "    \n",
    "    mean_area = np.nanmean(row['proportional_changes_sampled'])\n",
    "    sds = [np.sqrt(p*(1-p)) for p in row['proportional_changes_sampled']]\n",
    "    mean_sd = np.nanmean(sds)\n",
    "    se_area = np.divide(sd_area, np.sqrt(len(row['proportional_changes_sampled'])))\n",
    "    \n",
    "    #sd_area = np.nanstd(row['proportional_changes_sampled'])\n",
    "    #se_area = np.divide(sd_area, np.sqrt(len(row['proportional_changes_sampled'])))\n",
    "    #se_area = np.divide(sd_area, np.sqrt(row['sample_size']))\n",
    "    \n",
    "    ci = 1.96 * se_area\n",
    "    perc_uncertainty = ci/mean_area*100\n",
    "    \n",
    "    return mean_deviation, sd_deviation, mean_area, mean_sd, se_area, perc_uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebadef7-bb80-4ea8-8c8a-34d5ab7a05a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = 0.1  ## relative\n",
    "sample_size = calculate_sample_size_cochran(1129313, 372, target_precision=target)\n",
    "print(sample_size)\n",
    "calculate_error_cochran(1129313, 372, sample_size=sample_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe25cb6d-f96d-4690-a63d-cc1f117e9519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "for idx, sample_size in enumerate(range(10000, 500000, 10000)):\n",
    "    change_error = calculate_error_cochran(total_area = area_dict['total_area'],\n",
    "        subarea = area_dict['change_area'],\n",
    "        z_score=1.0,\n",
    "        sample_size=sample_size)\n",
    "    \n",
    "    forest_error = calculate_error_cochran(total_area = area_dict['total_area'],\n",
    "        subarea = area_dict['forest_area'],\n",
    "        z_score=1.645,\n",
    "        sample_size=sample_size)\n",
    "    \n",
    "    grid_size = np.sqrt(area_dict['total_area']/sample_size)\n",
    "    d[idx] = sample_size, forest_error, change_error, grid_size\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame.from_dict(d, orient='index')\n",
    "\n",
    "#display(df)\n",
    "df.columns = ['Sample Size', 'Theoretical Sampling Error (Forest)', 'Theoretical Sampling Error (Deforestation)', 'Grid Size']\n",
    "max_error = 5 # in percentage\n",
    "\n",
    "selected = df[df['Theoretical Sampling Error (Deforestation)'] < max_error].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d85edf3-a87c-4111-b9d4-800bc9920403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e74bb2-4517-453d-89e0-ccd09e097190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_grid_size = int(np.floor(selected['Grid Size'])*1000)\n",
    "selected_grid_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcffc39-e15b-4bbf-adbc-d5a3b6d36964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,7))\n",
    "df.plot.scatter(y='Theoretical Sampling Error (Forest)', x='Sample Size', ax=axes[0], color='green')\n",
    "df.plot.scatter(y='Theoretical Sampling Error (Deforestation)', x='Sample Size', ax=axes[0], color='orange')\n",
    "selected.plot.scatter(y='Theoretical Sampling Error (Deforestation)', x='Sample Size', ax=axes[0], color='blue')\n",
    "axes[0].legend(['Forest stable', 'Forest Change', 'Selected'])\n",
    "df.plot(kind='scatter', x='Sample Size', y='Grid Size', ax=axes[1],color='white')\n",
    "selected.plot(kind='scatter', x='Sample Size', y='Grid Size', ax=axes[1], color='blue')\n",
    "axes[0].set_facecolor(\"gainsboro\")\n",
    "axes[0].grid(color='white')\n",
    "axes[1].set_facecolor(\"gainsboro\")\n",
    "axes[1].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c923fbdf-7064-4f6b-a23c-0037d0f63e87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@retry(stop_max_attempt_number=5, wait_random_min=5000, wait_random_max=15000)\n",
    "def get_sampling_errors(aoi, start, end, collection, scale, proportional_change, nr_of_runs_per_grid, grid_sizes, random_seed):    \n",
    "    print(proportional_change)\n",
    "    # create random seeds\n",
    "    np.random.seed(random_seed)\n",
    "    seeds = np.random.random(nr_of_runs_per_grid)\n",
    "    seeds = list(np.round(np.multiply(seeds, 100), 0))\n",
    "    \n",
    "    if collection == 'CCI':\n",
    "\n",
    "        lc = ee.ImageCollection(\"users/amitghosh/sdg_module/esa/cci_landcover\")\n",
    "        lc_start = lc.filter(ee.Filter.eq(\"system:index\", f'{start}')).first()\n",
    "        lc_end = lc.filter(ee.Filter.eq(\"system:index\", f'{end}')).first()\n",
    "        change = lc_start.neq(lc_end).clip(aoi)\n",
    "        scale = 300\n",
    "\n",
    "    elif collection == 'GFC':\n",
    "\n",
    "        hansen = ee.Image(\"UMD/hansen/global_forest_change_2021_v1_9\").select('lossyear').unmask(0)\n",
    "        hansen = hansen.updateMask(hansen.mask().eq(1))\n",
    "        change = hansen.gte(ee.Number(start).subtract(2000)).And(hansen.lte(ee.Number(end).subtract(2000)))\n",
    "        scale = scale\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # nested function for getting proportional change per grid size\n",
    "    def get_grid_sample_error(grid):\n",
    "        \n",
    "        # set pixel size\n",
    "        proj = ee.Projection(\"EPSG:3857\").atScale(grid)\n",
    "        \n",
    "        # get total sample size\n",
    "        sample_size = ee.Image(1).rename('sample_size').reproject(proj).reduceRegion(**{\n",
    "            'reducer': ee.Reducer.sum(),\n",
    "            'geometry': aoi,\n",
    "            'scale': grid,\n",
    "            'maxPixels': 1e14\n",
    "        }).get('sample_size')\n",
    "        \n",
    "        \n",
    "        # -----------------------------------------------------------------\n",
    "        # nested function for getting proportional change per seed and grid\n",
    "        def get_sampled_proportional_change(seed, proj):\n",
    "\n",
    "            # create a subsample of our change image\n",
    "            cells = ee.Image.random(seed).multiply(1000000).int().reproject(proj)\n",
    "            random = ee.Image.random(seed).multiply(1000000).int()\n",
    "            maximum = cells.addBands(random).reduceConnectedComponents(ee.Reducer.max())\n",
    "            points = random.eq(maximum).selfMask().clip(aoi).reproject(proj.atScale(scale))\n",
    "\n",
    "            # create a stack with change and total pixels as 1\n",
    "            stack = (change.updateMask(points)          # masked sample change\n",
    "                .addBands(points)                       # all samples\n",
    "                .multiply(ee.Image.pixelArea())         # multiply both for pixel area\n",
    "                .rename(['sampled_change', 'sampled_area'])\n",
    "            )\n",
    "\n",
    "            # sum them up\n",
    "            areas = stack.reduceRegion(**{\n",
    "                'reducer': ee.Reducer.sum(),\n",
    "                'geometry': aoi,\n",
    "                'scale': scale,\n",
    "                'maxPixels': 1e14\n",
    "            })\n",
    "\n",
    "            # calculate proportional change to entire sampled area\n",
    "            proportional_change_sampled = ee.Number(areas.get('sampled_change')).divide(ee.Number(areas.get('sampled_area'))).getInfo()\n",
    "                        \n",
    "            return proportional_change_sampled\n",
    "        # -----------------------------------------------------------------\n",
    "        \n",
    "        # get sample error mean and stddev\n",
    "        proportional_changes_sampled = [get_sampled_proportional_change(seed, proj) for seed in seeds]\n",
    "        \n",
    "        # add to a dict of all grids\n",
    "        return proportional_changes_sampled, sample_size.getInfo()\n",
    "    \n",
    "    d, dfs = {}, []\n",
    "    # we map over all different grid sizes\n",
    "    print(f\" Running the sampling error simulation. Please be patient, this can take a while.\")\n",
    "    for idx, grid in enumerate(grid_sizes):\n",
    "        print(f\" Running {nr_of_runs_per_grid} times the sample error simulation at a scale of {grid} meter.\")\n",
    "        proportional_changes_sampled, sample_size = get_grid_sample_error(grid)\n",
    "        d['idx'] = idx\n",
    "        d['spacing'] = grid\n",
    "        d['sample_size'] = sample_size\n",
    "        d['proportional_changes_sampled'] = proportional_changes_sampled\n",
    "        dfs.append(pd.DataFrame([d]))\n",
    "    \n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10979caa-6c59-40d9-b8c0-5f209d026b24",
   "metadata": {},
   "source": [
    "SUM over no runs (cproport change of individual run- mean proport change over all runs)**2/(no runs -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bff1a31-8aa7-4dea-a802-f6c701bc6627",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cambodia\n",
      "According to the GFC product, the Area of Interest covers an area of 181423.76 square kilometers, of which 78371.69 square kilometers have been forested in 2015 (43.2 %). Between 2015 and 2020, 10833.91 square kilometers have been deforested. That corresponds to 1805.6516666666666 square kilometers of annual deforestation in average.\n",
      "0.05971604821771966\n",
      " Running the sampling error simulation. Please be patient, this can take a while.\n",
      " Running 25 times the sample error simulation at a scale of 500 meter.\n",
      " Running 25 times the sample error simulation at a scale of 1000 meter.\n",
      " Running 25 times the sample error simulation at a scale of 2000 meter.\n",
      " Running 25 times the sample error simulation at a scale of 4000 meter.\n",
      " Running 25 times the sample error simulation at a scale of 7500 meter.\n",
      " Running 25 times the sample error simulation at a scale of 10000 meter.\n",
      "0.05971604821771966\n",
      " Running the sampling error simulation. Please be patient, this can take a while.\n",
      " Running 25 times the sample error simulation at a scale of 500 meter.\n",
      " Running 25 times the sample error simulation at a scale of 1000 meter.\n",
      " Running 25 times the sample error simulation at a scale of 2000 meter.\n",
      " Running 25 times the sample error simulation at a scale of 4000 meter.\n",
      " Running 25 times the sample error simulation at a scale of 7500 meter.\n",
      " Running 25 times the sample error simulation at a scale of 10000 meter.\n",
      "0.05971604821771966\n",
      " Running the sampling error simulation. Please be patient, this can take a while.\n",
      " Running 25 times the sample error simulation at a scale of 500 meter.\n",
      " Running 25 times the sample error simulation at a scale of 1000 meter.\n",
      " Running 25 times the sample error simulation at a scale of 2000 meter.\n",
      " Running 25 times the sample error simulation at a scale of 4000 meter.\n",
      " Running 25 times the sample error simulation at a scale of 7500 meter.\n",
      " Running 25 times the sample error simulation at a scale of 10000 meter.\n",
      "0.05971604821771966\n",
      " Running the sampling error simulation. Please be patient, this can take a while.\n",
      " Running 25 times the sample error simulation at a scale of 500 meter.\n",
      " Running 25 times the sample error simulation at a scale of 1000 meter.\n",
      " Running 25 times the sample error simulation at a scale of 2000 meter.\n",
      " Running 25 times the sample error simulation at a scale of 4000 meter.\n",
      " Running 25 times the sample error simulation at a scale of 7500 meter.\n",
      " Running 25 times the sample error simulation at a scale of 10000 meter.\n",
      "Bangladesh\n",
      "According to the GFC product, the Area of Interest covers an area of 139824.77 square kilometers, of which 21355.19 square kilometers have been forested in 2015 (15.27 %). Between 2015 and 2020, 1609.5 square kilometers have been deforested. That corresponds to 268.25 square kilometers of annual deforestation in average.\n",
      "0.011510836027121663\n",
      " Running the sampling error simulation. Please be patient, this can take a while.\n",
      " Running 25 times the sample error simulation at a scale of 500 meter.\n",
      " Running 25 times the sample error simulation at a scale of 1000 meter.\n",
      " Running 25 times the sample error simulation at a scale of 2000 meter.\n",
      " Running 25 times the sample error simulation at a scale of 4000 meter.\n",
      " Running 25 times the sample error simulation at a scale of 7500 meter.\n",
      " Running 25 times the sample error simulation at a scale of 10000 meter.\n",
      "0.011510836027121663\n",
      " Running the sampling error simulation. Please be patient, this can take a while.\n",
      " Running 25 times the sample error simulation at a scale of 500 meter.\n",
      " Running 25 times the sample error simulation at a scale of 1000 meter.\n",
      " Running 25 times the sample error simulation at a scale of 2000 meter.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def add_stats(row, actual_proportional):\n",
    "    \n",
    "    abs_errors = [np.abs(np.subtract(i, actual_proportional)) for i in row['proportional_changes_sampled']]\n",
    "    mean_deviation, sd_deviation = np.nanmean(abs_errors), np.nanstd(abs_errors)\n",
    "    \n",
    "    mean_area = np.nanmean(row['proportional_changes_sampled']), \n",
    "    sd_area = np.nanstd(row['proportional_changes_sampled'])\n",
    "    se_area = np.divide(sd_area, np.sqrt(len(row['proportional_changes_sampled'])))\n",
    "    proportional_se = np.sqrt(sd_area**2)/actual_proportional*100\n",
    "    \n",
    "    return mean_deviation, sd_deviation, mean_area, sd_area, se_area, proportional_se\n",
    "\n",
    "# based on earth engine feature collection\n",
    "country = 'Zambia'\n",
    "\n",
    "\n",
    "for country in [\n",
    "    #'Liberia', 'Ethiopia', 'Kenya', 'Zambia', #'Uganda', \n",
    "    #'Ecuador', \n",
    "    #'Paraguay', 'Guyana', #'Peru', 'Colombia'\n",
    "    #'Fiji', 'Viet Nam', 'Ghana', \n",
    "    'Cambodia', 'Bangladesh', 'Papua New Guinea'\n",
    "]:\n",
    "    \n",
    "    print(country)\n",
    "    # get AOI\n",
    "    gaul = ee.FeatureCollection(\"FAO/GAUL/2015/level1\")\n",
    "    aoi = gaul.filter(ee.Filter.eq(\"ADM0_NAME\", country)).union()\n",
    "    \n",
    "    # get actual Hansen areas\n",
    "    area_dict = get_aoi_areas(aoi, 'GFC', start_year, end_year, tree_cover)\n",
    "    \n",
    "    # do sampling simulation at different scales\n",
    "    for scale in [30, 70, 100, 250]:\n",
    "        \n",
    "        if Path(f'{country}_25_runs_{scale}_scale.pickle').exists():\n",
    "            continue\n",
    "            \n",
    "        grid_sizes = [500, 1000, 2000, 4000, 7500, 10000]\n",
    "        df = get_sampling_errors(\n",
    "            aoi, start_year, end_year, 'GFC', scale, \n",
    "            area_dict['change_area']/area_dict['total_area'], \n",
    "            25, grid_sizes, 7\n",
    "        )\n",
    "        df.to_pickle(f'{country}_25_runs_{scale}_scale.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8861c24a-08c8-4441-af6f-3abf2bc22a17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "actual_proportion = area_dict['change_area']/area_dict['total_area']\n",
    "print(actual_proportion)\n",
    "df = pd.read_pickle('zambia_10runs.pickle')\n",
    "df[['mean', 'sd', 'mean_area', 'sd_area', 'se_area', 'proportional_error']] = df.apply(lambda x: add_stats(x, actual_proportion), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9681b176-0507-4d3c-8496-00bb82a1e32b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(df)\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "ax = df.plot(x='sample_size', y='proportional_error',  kind='scatter')\n",
    "#ax.set_xscale('log')\n",
    "ax.ticklabel_format(useOffset=False, style='plain')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_eSBAE2",
   "language": "python",
   "name": "venv_esbae2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
